{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-01 15:32:56.796746\n",
      "fail to dowload the page, reason: \n",
      "HTTPConnectionPool(host='sh.lianjia.com', port=80): Max retries exceeded with url: /xiaoqu/5011000017980.html (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000024B77F48E80>: Failed to establish a new connection: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。',))\n",
      "try again\n",
      "上海康城 40508  31.10631595 121.362808 莘松路958弄（大浪湾道01-61号、山林道04-96号、江山道01-23号、瀑布湾道21-96号、维园道01-45号、康城道51-82） 住宅 - 公寓 2008年建\n",
      "\n",
      "中远两湾城 73305  31.259226 121.451405 中潭路33弄,远景路97弄,中潭路99弄,中潭路100弄,中潭路91弄 住宅 - 公寓 2006年建\n",
      "\n",
      "奥林匹克花园 48850  31.15272248 121.3362569 涞亭北路99弄,涞寅路106弄 住宅 - 公寓 2010年建\n",
      "\n",
      "新城金郡 36539  31.34873307 121.2462989 临泽路88弄, 临泽路89弄, 临泽路188弄, 临泽路189弄, 云屏路1399弄, 崇信路1518弄, 白银路1565号, 白银路1563号 住宅 - 公寓、商住、住宅 - 写字楼 2013年建\n",
      "\n",
      "绿洲康城亲水湾 56919  31.158247 121.590724 康桥路1259弄, 康桥路1558弄, 康桥路1633弄, 康桥路1657弄 住宅 - 公寓 2017年建\n",
      "\n",
      "保利叶上海（公寓） 57726  31.35350639 121.3651601 联杨路1078弄，菊联路262弄，菊太路1198弄 住宅 - 公寓 2012年建\n",
      "\n",
      "证大家园（公寓） 77255  31.28632734 121.6028134 五莲路1728弄，巨峰路399弄，五莲路1769弄，利津路1313弄，巨峰路667弄 住宅 - 公寓 2006年建\n",
      "\n",
      "新凯家园 38366  31.11265928 121.2400431 新家园路128弄, 新家园路30弄，新家园路88弄，古楼公路1858弄 住宅 - 公寓 2015年建\n",
      "\n",
      "艺泰安邦 32734  31.067346 121.715747 南六公路399弄 住宅 - 公寓 2013年建\n",
      "\n",
      "世茂滨江花园 90523  31.227414 121.520399 潍坊西路1弄,潍坊西路2弄 住宅 - 公寓 2009年建\n",
      "\n",
      "同润菲诗艾伦 40989  31.111525 121.258141 古楼公路1198弄 住宅 - 公寓 2012年建\n",
      "\n",
      "仁恒河滨城 102010  31.234586 121.57339 丁香路1399弄，丁香路1299弄，丁香路1599弄 住宅 - 公寓 2009年建\n",
      "\n",
      "绿地威廉公寓 61118  31.297808 121.619963 东靖路2250弄 住宅 - 公寓 2013年建\n",
      "\n",
      "九城湖滨国际 51803  31.155467 121.32503 沪亭北路618弄 住宅 - 公寓 2009年建\n",
      "\n",
      "合景峰汇 25345  31.350562 121.264357 天祝路555弄 商住 2013年建\n",
      "\n",
      "绿地康桥新苑 53075  31.144155 121.571294 沪南路2688弄 住宅 - 公寓 2007年建\n",
      "\n",
      "经纬城市绿洲 53446  31.334703 121.402008 纬地路99弄, 涵青路100弄, 纬地路88弄 住宅 - 公寓 2010年建\n",
      "\n",
      "贝港南区 25873  30.914748 121.452703 贝港新村 住宅 - 公寓 1998年建\n",
      "\n",
      "新南家园 31444  31.000021 121.452144 西闸公路1118弄,扶港路399弄,新南家园 住宅 - 公寓、商铺 2010年建\n",
      "\n",
      "绿庭尚城 48201  31.153101 121.31917 涞寅路658弄 住宅 - 公寓 2013年建\n",
      "\n",
      "main1 ended\n",
      "2016-12-01 15:34:02.780821\n",
      "Total time running m1: 0:01:05.984075 seconds\n",
      "2016-12-01 15:34:02.780821\n",
      "上海康城 /xiaoqu/5011102207057.html 40508  31.10631595 121.362808 莘松路958弄（大浪湾道01-61号、山林道04-96号、江山道01-23号、瀑布湾道21-96号、维园道01-45号、康城道51-82） 住宅 - 公寓 2008年建\n",
      "\n",
      "中远两湾城 /xiaoqu/5011000014141.html 73305  31.259226 121.451405 中潭路33弄,远景路97弄,中潭路99弄,中潭路100弄,中潭路91弄 住宅 - 公寓 2006年建\n",
      "\n",
      "奥林匹克花园 /xiaoqu/5011000015174.html 48850  31.15272248 121.3362569 涞亭北路99弄,涞寅路106弄 住宅 - 公寓 2010年建\n",
      "\n",
      "新城金郡 /xiaoqu/5011000009660.html 36539  31.34873307 121.2462989 临泽路88弄, 临泽路89弄, 临泽路188弄, 临泽路189弄, 云屏路1399弄, 崇信路1518弄, 白银路1565号, 白银路1563号 住宅 - 公寓、商住、住宅 - 写字楼 2013年建\n",
      "\n",
      "绿洲康城亲水湾 /xiaoqu/5011000013546.html 56919  31.158247 121.590724 康桥路1259弄, 康桥路1558弄, 康桥路1633弄, 康桥路1657弄 住宅 - 公寓 2017年建\n",
      "\n",
      "保利叶上海（公寓） /xiaoqu/5011102210422.html 57726  31.35350639 121.3651601 联杨路1078弄，菊联路262弄，菊太路1198弄 住宅 - 公寓 2012年建\n",
      "\n",
      "证大家园（公寓） /xiaoqu/5011102209345.html 77255  31.28632734 121.6028134 五莲路1728弄，巨峰路399弄，五莲路1769弄，利津路1313弄，巨峰路667弄 住宅 - 公寓 2006年建\n",
      "\n",
      "新凯家园 /xiaoqu/5011102207146.html 38366  31.11265928 121.2400431 新家园路128弄, 新家园路30弄，新家园路88弄，古楼公路1858弄 住宅 - 公寓 2015年建\n",
      "\n",
      "艺泰安邦 /xiaoqu/5011000012807.html 32734  31.067346 121.715747 南六公路399弄 住宅 - 公寓 2013年建\n",
      "\n",
      "世茂滨江花园 /xiaoqu/5011000017872.html 90523  31.227414 121.520399 潍坊西路1弄,潍坊西路2弄 住宅 - 公寓 2009年建\n",
      "\n",
      "同润菲诗艾伦 /xiaoqu/5011000014575.html 40989  31.111525 121.258141 古楼公路1198弄 住宅 - 公寓 2012年建\n",
      "\n",
      "仁恒河滨城 /xiaoqu/5011000017980.html 102010  31.234586 121.57339 丁香路1399弄，丁香路1299弄，丁香路1599弄 住宅 - 公寓 2009年建\n",
      "\n",
      "绿地威廉公寓 /xiaoqu/5011000013063.html 61118  31.297808 121.619963 东靖路2250弄 住宅 - 公寓 2013年建\n",
      "\n",
      "九城湖滨国际 /xiaoqu/5011000014093.html 51803  31.155467 121.32503 沪亭北路618弄 住宅 - 公寓 2009年建\n",
      "\n",
      "合景峰汇 /xiaoqu/5011000005209.html 25345  31.350562 121.264357 天祝路555弄 商住 2013年建\n",
      "\n",
      "绿地康桥新苑 /xiaoqu/5011000017528.html 53075  31.144155 121.571294 沪南路2688弄 住宅 - 公寓 2007年建\n",
      "\n",
      "经纬城市绿洲 /xiaoqu/5011000015938.html 53446  31.334703 121.402008 纬地路99弄, 涵青路100弄, 纬地路88弄 住宅 - 公寓 2010年建\n",
      "\n",
      "贝港南区 /xiaoqu/5011000012143.html 25873  30.914748 121.452703 贝港新村 住宅 - 公寓 1998年建\n",
      "\n",
      "新南家园 /xiaoqu/5011000012357.html 31444  31.000021 121.452144 西闸公路1118弄,扶港路399弄,新南家园 住宅 - 公寓、商铺 2010年建\n",
      "\n",
      "绿庭尚城 /xiaoqu/5011000014071.html 48201  31.153101 121.31917 涞寅路658弄 住宅 - 公寓 2013年建\n",
      "\n",
      "main2 ended\n",
      "2016-12-01 15:34:48.675876\n",
      "Total time running m2: 0:00:45.895055 seconds\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    " \n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from functools import wraps\n",
    "\n",
    "\n",
    "def fn_timer(function):\n",
    "    @wraps(function)\n",
    "    def function_timer(*args, **kwargs):\n",
    "        t0 = datetime.datetime.now()\n",
    "        print(t0)\n",
    "        result = function(*args, **kwargs)\n",
    "        t1 = datetime.datetime.now()\n",
    "        print(t1)\n",
    "        print(\"Total time running %s: %s seconds\" %\n",
    "              (function.__name__, str(t1 - t0))\n",
    "              )\n",
    "        return result\n",
    "\n",
    "    return function_timer\n",
    "def fn_timer_microsecond(function):\n",
    "    @wraps(function)\n",
    "    def function_timer(*args, **kwargs):\n",
    "        t0 = datetime.datetime.now().microsecond\n",
    "        print(datetime.datetime.now())\n",
    "        result = function(*args, **kwargs)\n",
    "        t1 = datetime.datetime.now().microsecond\n",
    "        print(datetime.datetime.now())\n",
    "        print(\"Total time running %s: %s seconds\" %\n",
    "              (function.__name__, str(t1 - t0))\n",
    "              )\n",
    "        return result\n",
    "\n",
    "    return function_timer\n",
    "\n",
    "URL = 'http://sh.lianjia.com'\n",
    "xiaoqu_url = 'http://sh.lianjia.com/xiaoqu/d'\n",
    "detail_url = 'http://sh.lianjia.com/xiaoqu/5011102207057.html'\n",
    "\n",
    "\n",
    "\n",
    "def download_page(url, retries=3):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0'}\n",
    "    try:\n",
    "        data = requests.get(url, headers=headers).content\n",
    "    except Exception as err:\n",
    "        print(\"fail to dowload the page, reason: \")\n",
    "        print(err)\n",
    "        if retries>0:\n",
    "            print(\"try again\")\n",
    "            return download_page(url,retries-1)\n",
    "        else:\n",
    "            print(\"failed in scaping : %s\" % url)\n",
    "            return ''        \n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def parse_page(html):\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    link_list = []\n",
    "    name_list = []\n",
    "    xiaoqu_list = soup.findAll('div', attrs={'class': 'info-panel'})\n",
    "    # print(xiaoqu_list)\n",
    "\n",
    "    for xiaoqu in xiaoqu_list:\n",
    "        link = xiaoqu.find('a').get('href')\n",
    "        name = xiaoqu.find('a').get('title')\n",
    "        link_list.append(link)\n",
    "    \n",
    "    for link in link_list:\n",
    "        \n",
    "        parse_detail_page(link)\n",
    "\n",
    "\n",
    "def parse_detail_page(link):\n",
    "    result = ' '\n",
    "    detail_link = URL + link\n",
    "    detail_soup = BeautifulSoup(download_page(detail_link),\"html.parser\")\n",
    "    # get the price\n",
    "    price = detail_soup.find('span',attrs={'class':'p'}).getText().strip()\n",
    "\n",
    "    # get name, latitude and longitude\n",
    "    coord = detail_soup.find('a',attrs={'class':'actshowMap'}).get('xiaoqu')\n",
    "\n",
    "    coord = coord.split(',')\n",
    "\n",
    "    latitude = coord[1]\n",
    "    longitude = coord[0].strip('[')\n",
    "    # name = coord[2].strip(']').strip(\"'\")\n",
    "    name = coord[2][2:-2]\n",
    "\n",
    "    # get address\n",
    "    adr = detail_soup.find('span',attrs={'class':'adr'}).getText().strip()\n",
    "\n",
    "    result = name + ' ' + link + ' ' + price + ' ' + latitude + ' ' + longitude + ' ' + adr\n",
    "\n",
    "    # get other info\n",
    "    others = []\n",
    "    other_info = detail_soup.findAll('span',attrs={'class':'other'})\n",
    "    # print(other_info)\n",
    "    for info in other_info:\n",
    "        # print(info.getText())\n",
    "        # print(info.getText().strip())\n",
    "        others.append(info.getText().strip())\n",
    "    \n",
    "    \n",
    "    i = 1\n",
    "    for other in others:\n",
    "        if i<3:\n",
    "            result += ' ' + other\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    "  \n",
    "    result +=  '\\n'\n",
    "    print(result)\n",
    "    with open('shanghai_old.txt', 'a') as f:\n",
    "        f.write(result)\n",
    "    \n",
    "    # time.sleep(0.5)\n",
    "\n",
    "def parse_detail_page_test(html):\n",
    "\n",
    "    detail_soup = BeautifulSoup(html,\"html.parser\")\n",
    "    # get the price\n",
    "    price = detail_soup.find('span',attrs={'class':'p'}).getText().strip()\n",
    "\n",
    "    # get name, latitude and longitude\n",
    "    coord = detail_soup.find('a',attrs={'class':'actshowMap'}).get('xiaoqu')\n",
    "\n",
    "    coord = coord.split(',')\n",
    "\n",
    "    latitude = coord[1]\n",
    "    longitude = coord[0].strip('[')\n",
    "    # name = coord[2].strip(']').strip(\"'\")\n",
    "    name = coord[2][2:-2]\n",
    "\n",
    "    # get address\n",
    "    adr = detail_soup.find('span',attrs={'class':'adr'}).getText().strip()\n",
    "\n",
    "#     result = name + ' ' + link + ' ' + price + ' ' + latitude + ' ' + longitude + ' ' + adr\n",
    "    result = name + ' ' + price + ' ' + latitude + ' ' + longitude + ' ' + adr\n",
    "\n",
    "\n",
    "    # get other info\n",
    "    others = []\n",
    "    other_info = detail_soup.findAll('span',attrs={'class':'other'})\n",
    "    # print(other_info)\n",
    "    for info in other_info:\n",
    "        # print(info.getText())\n",
    "        # print(info.getText().strip())\n",
    "        others.append(info.getText().strip())\n",
    "    \n",
    "    \n",
    "    i = 1\n",
    "    for other in others:\n",
    "        if i<3:\n",
    "            result += ' ' + other\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    "  \n",
    "    result +=  '\\n'\n",
    "    print(result)\n",
    "    with open('shanghai_new.txt', 'a') as f:\n",
    "        f.write(result)\n",
    "    \n",
    "    # time.sleep(0.5)\n",
    "    \n",
    "    \n",
    "def parse_page_test(html):\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    link_list = []\n",
    "    name_list = []\n",
    "    xiaoqu_list = soup.findAll('div', attrs={'class': 'info-panel'})\n",
    "    # print(xiaoqu_list)\n",
    "\n",
    "    for xiaoqu in xiaoqu_list:\n",
    "        link = xiaoqu.find('a').get('href')\n",
    "        detail_link = URL + link\n",
    "        link_list.append(detail_link)\n",
    "    \n",
    "    return link_list\n",
    "\n",
    "@fn_timer\n",
    "def m1():\n",
    "    \n",
    "    url = xiaoqu_url + '1'\n",
    "    html = download_page(url)\n",
    "    urls = parse_page_test(html)\n",
    "     \n",
    "    pool = ThreadPool()\n",
    "\n",
    "#     results = pool.map(urllib.request.urlopen,urls)\n",
    "    results = pool.map(download_page,urls)\n",
    "#     print(results)\n",
    "    for http_obj in results:\n",
    "        parse_detail_page_test(http_obj)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    print('main1 ended')\n",
    "    # detail_soup = BeautifulSoup(download_page(detail_url),\"html.parser\")\n",
    "    # coord = detail_soup.find('a',attrs={'class':'actshowMap'}).get('xiaoqu')\n",
    "    \n",
    "    # parse_detail_page('hh', detail_url)\n",
    "    # a = \"'绿地威廉公寓']\"\n",
    "    # print(a)\n",
    "    # print(a[1:-2])\n",
    "    # print(a.strip(\"]\").strip(\"'\"))\n",
    "    # a = a.strip(\"'\")\n",
    "    # print(a)\n",
    "\n",
    "#     url = xiaoqu_url + '1'\n",
    "#     html = download_page(url)\n",
    "#     parse_page(html)\n",
    "\n",
    " \n",
    "#     for i in range(89,101):\n",
    "        \n",
    "#         url = xiaoqu_url + str(i)\n",
    "#         print(\"start scraping \" + url)\n",
    "#     # url = xiaoqu_url\n",
    "#         html = download_page(url)\n",
    "#         parse_page(html)\n",
    "#         print(\"# ----------------- got page %d !!!\" % i)\n",
    "\n",
    "    # while url:\n",
    "    #     html = download_page(url)\n",
    "    #     movies, url = parse_page(html)\n",
    "    #     print(movies)\n",
    "        #print('--------------------------------------------------------------------------------------')\n",
    "@fn_timer\n",
    "def m2():\n",
    "    \n",
    "#     url = xiaoqu_url + '1'\n",
    "#     html = download_page(url)\n",
    "#     urls = parse_page_test(html)\n",
    "     \n",
    "#     pool = ThreadPool()\n",
    "\n",
    "# #     results = pool.map(urllib.request.urlopen,urls)\n",
    "#     results = pool.map(download_page,urls)\n",
    "# #     print(results)\n",
    "#     for http_obj in results:\n",
    "#         parse_detail_page_test(http_obj)\n",
    "#     pool.close()\n",
    "#     pool.join()\n",
    "\n",
    "#     print('main ended')\n",
    "    # detail_soup = BeautifulSoup(download_page(detail_url),\"html.parser\")\n",
    "    # coord = detail_soup.find('a',attrs={'class':'actshowMap'}).get('xiaoqu')\n",
    "    \n",
    "    # parse_detail_page('hh', detail_url)\n",
    "    # a = \"'绿地威廉公寓']\"\n",
    "    # print(a)\n",
    "    # print(a[1:-2])\n",
    "    # print(a.strip(\"]\").strip(\"'\"))\n",
    "    # a = a.strip(\"'\")\n",
    "    # print(a)\n",
    "\n",
    "    url = xiaoqu_url + '1'\n",
    "    html = download_page(url)\n",
    "    parse_page(html)\n",
    "    print('main2 ended')\n",
    "\n",
    "#     for i in range(89,101):       \n",
    "#         url = xiaoqu_url + str(i)\n",
    "#         print(\"start scraping \" + url)\n",
    "#     # url = xiaoqu_url\n",
    "#         html = download_page(url)\n",
    "#         parse_page(html)\n",
    "#         print(\"# ----------------- got page %d !!!\" % i)\n",
    "\n",
    "    # while url:\n",
    "    #     html = download_page(url)\n",
    "    #     movies, url = parse_page(html)\n",
    "    #     print(movies)\n",
    "        #print('--------------------------------------------------------------------------------------')\n",
    "def main():\n",
    "    m1()\n",
    "    m2()\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    print('good')\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
